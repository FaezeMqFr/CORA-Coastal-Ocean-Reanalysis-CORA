{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6fc216-c8ff-4124-94f1-c8284f25f8f0",
   "metadata": {
    "id": "8d6fc216-c8ff-4124-94f1-c8284f25f8f0"
   },
   "source": [
    "# This notebook allow users to pull NOAA Coastal Ocean ReAnalysis (CORA) data that is stored on NOAA's Open Data Dissemination (NODD) service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75784115-8273-47d0-8004-6ea1e68b96dd",
   "metadata": {},
   "source": [
    "## Import your python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958b2122-9b8e-411b-a6f0-98f591fb8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "packages = [\"requests\",\"numpy\",\"matplotlib.pyplot\",\"pandas\",\"dask\",\"intake\",\"intake-xarray\",\"scipy\",\"s3fs\",\"geopy\",\"folium\",\"branca.colormap\"]\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973908ab-5c69-4775-ad1f-dccafc8deef0",
   "metadata": {
    "id": "973908ab-5c69-4775-ad1f-dccafc8deef0"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask\n",
    "import intake\n",
    "import xarray as xr\n",
    "import scipy.spatial as sp\n",
    "import s3fs\n",
    "import geopy.distance\n",
    "from scipy.spatial import KDTree\n",
    "import folium\n",
    "from folium import Marker\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "from branca.colormap import linear, LinearColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef0505-ce20-4f42-895d-d0f9dfab4e6f",
   "metadata": {},
   "source": [
    "**Access the data on the NODD and initialize the available CORA datasets.** \n",
    "\n",
    "*This accesses a .yml file located on the NODD that shows which CORA output files are available to import.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ee33db-10b7-4cd1-887d-7b0aaced1d04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09ee33db-10b7-4cd1-887d-7b0aaced1d04",
    "outputId": "370bff26-6e85-46df-c299-13bd494dfe3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CORA-V1-fort.63',\n",
       " 'CORA-V1-maxele.63',\n",
       " 'CORA-V1-fort.64',\n",
       " 'CORA-V1-500m-grid-1979-2022']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title This accesses a .yml file located on the NODD that shows which CORA output files are available to import.\n",
    "catalog = intake.open_catalog(\"s3://noaa-nos-cora-pds/CORA_intake.yml\",storage_options={'anon':True})\n",
    "list(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ecccc-4203-41d4-8d98-4ca8369433f0",
   "metadata": {
    "id": "de2ecccc-4203-41d4-8d98-4ca8369433f0"
   },
   "source": [
    "**The CORA-V1-fort.63 file contains hourly water levels at the model mesh nodes for 1979-2022. The CORA-V1-maxele.63 file contains the maximum water level for the entire 1979-2022 period modeled at each of the model nodes. The CORA-V1-fort.64 file contains the hourly current velocities (u and v) at each of the model nodes for 1979-2022. The CORA-V1-500m-grid-1979-2022 file contains hourly water levels that have been interpolated from the model mesh nodes to uniformly space 500-meter grid nodes.**\n",
    "\n",
    "*Create an xarray dataset for the CORA data that you would like to use.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51cd6d9-b6ba-4f8d-8eb9-db5f17ebda33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f51cd6d9-b6ba-4f8d-8eb9-db5f17ebda33",
    "outputId": "1bd11d46-cbdb-463f-ada8-049b357a2d97"
   },
   "outputs": [],
   "source": [
    "ds = catalog[\"CORA-V1-fort.63\"].to_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33108bd1-fa7b-4c80-8453-712e48ff5235",
   "metadata": {},
   "source": [
    "## Which points would you like to query? I'm using Gulf and East Coast NWLON stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc34e1-ee39-4982-8f58-ea0b665639f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationpointsfile = 'C:\\\\Users\\\\John.Ratcliff\\\\CORA\\\\HSOFS_GEC_Stations.csv'\n",
    "cora_stations = pd.read_csv(stationpointsfile)\n",
    "cora_stations['id'] = cora_stations['id'].astype(str)\n",
    "cora_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728022f-061b-420e-95ae-b1456c72c6da",
   "metadata": {},
   "source": [
    "## The following 3 cells contain functions that are used to find mesh elements that contain your points. These could be saved together in a separate file and just run the file here, if you would like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4ddca5-5eb1-4352-a3cd-e33b8493cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(x1, y1, x2, y2, x3, y3):\n",
    " \n",
    "    return (abs((x1 * (y2 - y3) + x2 * (y3 - y1)\n",
    "                + x3 * (y1 - y2)) / 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101b32a3-9f56-463e-b1d0-32b92dc1d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kd_tree(ds):\n",
    "    e = ds.element.values.astype(int)\n",
    "    emin1 = e-1\n",
    "    num_elems = len(e)\n",
    "    x_vals = ds.x.values\n",
    "    y_vals = ds.y.values\n",
    "\n",
    "    xe=np.mean(x_vals[emin1],axis=1)\n",
    "    ye=np.mean(y_vals[emin1],axis=1)\n",
    "    tree = sp.KDTree(np.c_[xe,ye])\n",
    "    areas = [area(x_vals[emin1[k][0]],y_vals[emin1[k][0]],\\\n",
    "                  x_vals[emin1[k][1]],y_vals[emin1[k][1]],\\\n",
    "                  x_vals[emin1[k][2]],y_vals[emin1[k][2]])for k in range(0, num_elems)]\n",
    "    return tree, areas, e, x_vals, y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dee104f-6328-4d64-8adc-a32bf441b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triangle(x_vals, y_vals, e,lat,lon):\n",
    "    e = ds.element.values.astype(int)-1\n",
    "\n",
    "    k = 10\n",
    "    # Initialize an empty array to store triangle indices\n",
    "    triangle_i_arr = np.empty(len(lat), dtype=int)\n",
    "\n",
    "    # Iterate over each latitude and longitude pair\n",
    "    for i in range(len(lat)):\n",
    "        dist, ii= tree.query([lon.iloc[i],lat.iloc[i]],k=k)  # Query with individual point\n",
    "        ii = ii\n",
    "        triangle_i = -1\n",
    "\n",
    "        for j in range(0,k):\n",
    "\n",
    "\n",
    "            a1 = area(lon.iloc[i],lat.iloc[i],\\\n",
    "                      x_vals[e[ii[j]][0]],y_vals[e[ii[j]][0]],\\\n",
    "                      x_vals[e[ii[j]][1]],y_vals[e[ii[j]][1]])\n",
    "\n",
    "            a2 = area(lon.iloc[i],lat.iloc[i],\\\n",
    "                      x_vals[e[ii[j]][1]],y_vals[e[ii[j]][1]],\\\n",
    "                      x_vals[e[ii[j]][2]],y_vals[e[ii[j]][2]])\n",
    "            a3 = area(lon.iloc[i],lat.iloc[i],\\\n",
    "                      x_vals[e[ii[j]][0]],y_vals[e[ii[j]][0]],\\\n",
    "                      x_vals[e[ii[j]][2]],y_vals[e[ii[j]][2]])\n",
    "\n",
    "            t_area = a1 + a2 + a3\n",
    "            if abs(t_area - areas[ii[j]]) < 0.00000001:\n",
    "                triangle_i = ii[j] + 1\n",
    "                break\n",
    "\n",
    "        triangle_i_arr[i] = triangle_i # Store the triangle index for this point\n",
    "\n",
    "    # Check if any points failed to find a triangle\n",
    "    if np.any(triangle_i_arr == -1):\n",
    "        error_indices = np.where(triangle_i_arr == -1)[0]\n",
    "        print(\"ERROR for \", lat.iloc[error_indices], lon.iloc[error_indices])\n",
    "\n",
    "    return triangle_i_arr # Return the array of triangle indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683cff3-415f-4cad-a2c9-d7dd383a85cf",
   "metadata": {},
   "source": [
    "## The following tree variable is used with find_triangle to query the mesh element that contains your points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c69af-8bf3-450f-abe1-02b52ea217ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tree, areas, e, x_vals, y_vals = define_kd_tree(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a3527-03ad-4218-9163-56e2716567cf",
   "metadata": {},
   "source": [
    "## Here, we will do a weighted interpolation of the water levels from nearby nodes to our point of interest. We find our elements that contain our station points and also find the nearest nodes using KDTree. If we find an element, we use the nodes that make up the vertices of that element. If we don't find an element (maybe our point is just outside the mesh), then we can use nearest nodes. If any of our nearby nodes are dry, then our interpolation brings back a nan value. In that case, we will just use the mean of the other two nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d166da-74e9-40da-bbc5-d2ac94aab026",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GeIfkfN4ZQ8",
    "outputId": "97e1cc0c-cff5-4b06-c17d-3e02232d3e85"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Extract node coordinates from the mesh\n",
    "node_coords = np.c_[ds.x.values, ds.y.values]\n",
    "\n",
    "# Build the KDTree for finding nearest neighbor nodes\n",
    "nodetree = sp.KDTree(node_coords)\n",
    "\n",
    "elem_nodes = np.zeros((len(cora_stations), 3), dtype=int)\n",
    "query_point = np.zeros((len(cora_stations), 2))  # Assuming you want 2 columns for lat and lon\n",
    "eucl_dist = np.zeros((len(cora_stations), 3))    # Assuming you want 3 nearest neighbors\n",
    "nearest = np.zeros((len(cora_stations), 3), dtype=int)  # Assuming you want 3 nearest neighbors\n",
    "# elem_within = np.empty((len(stations_df), 1), dtype=int)  # Assuming you want 3 nearest elements\n",
    "dist = np.zeros((len(cora_stations), 3), dtype=float)\n",
    "weights = np.zeros((len(cora_stations), 3), dtype=float)\n",
    "geo_dist = np.zeros((len(cora_stations), 3), dtype=float)\n",
    "\n",
    "elem = find_triangle(x_vals,y_vals,e,cora_stations.lat,cora_stations.lon)\n",
    "\n",
    "for i in range(0,len(cora_stations)):\n",
    "\n",
    "    eucl_dist[i,:], nearest[i,:] = nodetree.query([cora_stations.lon.iloc[i],cora_stations.lat.iloc[i]], k=3) # query nearest nodes; shouldn't use euclidean distance result\n",
    "\n",
    "    nearest[i,:] = nearest[i,:] + 1\n",
    "\n",
    "    if elem[i]==-1:\n",
    "        elem_nodes[i,:] = nearest[i,:]\n",
    "    else:\n",
    "        elem_nodes[i,:] = e[elem[i]-1]\n",
    "\n",
    "    # compute geodesic distances between your station point and the nearby nodes\n",
    "    for j in range(3):\n",
    "        geo_dist[i, j] = geopy.distance.geodesic(\n",
    "            (cora_stations.lat.iloc[i], cora_stations.lon.iloc[i]),\n",
    "            (y_vals[elem_nodes[i, j]-1], x_vals[elem_nodes[i, j]-1])\n",
    "        ).km\n",
    "        if geo_dist[i, j] == 0:\n",
    "            weights[i, j] = 1\n",
    "        else:\n",
    "            weights[i, j] = 1 / geo_dist[i, j]\n",
    "\n",
    "unique_nodes = np.unique(elem_nodes) # sorted unique nodes\n",
    "mapped_triangle = np.searchsorted(unique_nodes, elem_nodes) # indices of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66947909-3feb-46cc-9df1-89e89a3e1481",
   "metadata": {},
   "source": [
    "## Make a list of all the node coordinates that we are using so we can plot them with our station points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef1688-5a92-4623-a102-982409432e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_nodes=np.concatenate(node_coords[elem_nodes-1], axis=0)\n",
    "lat_nodes=concat_nodes[:,1]\n",
    "lon_nodes=concat_nodes[:,0]\n",
    "df_nodes=pd.DataFrame({'Lon': lon_nodes, 'Lat': lat_nodes})\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca034928-8530-4db8-99d9-448f0dfc77d3",
   "metadata": {},
   "source": [
    "## Using folium, we can plot the points to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37d6c9-0dd0-4271-9a5b-effbf5c3446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a base map centered on the first coordinate\n",
    "map_center = [df_nodes['Lat'].mean(), df_nodes['Lon'].mean()]\n",
    "my_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Add markers for each coordinate\n",
    "for index, row in df_nodes.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Lat'], row['Lon']],\n",
    "    ).add_to(my_map)\n",
    "\n",
    "for index, row in cora_stations.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        popup=row['id'], color='red'\n",
    "    ).add_to(my_map)\n",
    "\n",
    "tile = folium.TileLayer(\n",
    "        tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr = 'Esri',\n",
    "        name = 'Esri Satellite',\n",
    "        overlay = False,\n",
    "        control = True\n",
    "       ).add_to(my_map)\n",
    "# Save the map to an HTML file\n",
    "# my_map.save(\"nodesmap.html\")\n",
    "\n",
    "my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ebcff-c865-4b88-b8eb-eb06def60374",
   "metadata": {},
   "source": [
    "## Now, we can grab a time slice of data at our model nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e754e-ae67-4161-aef1-cae7b66ba6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start_t = \"2018-09-10 00:00:00\"\n",
    "end_t = \"2018-09-18 23:00:00\"\n",
    "dt_range = pd.date_range(start_t, end_t, freq='h',inclusive='both')\n",
    "\n",
    "zeta_tslice = ds[\"zeta\"].sel(time=slice(start_t, end_t), node=unique_nodes-1).compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e503e-e429-4e74-8a4f-6688437fc6d2",
   "metadata": {},
   "source": [
    "## The distance weighted interpolation (or applied mean) is done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c25e52-27a9-4483-8538-bd22280318b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_ts = len(zeta_tslice)\n",
    "zeta_point = np.zeros((num_ts), dtype=float) # preallocate with zeros\n",
    "mean_zeta = np.zeros((num_ts,len(cora_stations)), dtype=float)\n",
    "zeta_df = pd.DataFrame({'time': dt_range}) # Initialize df with 'time' column\n",
    "zeta_df.set_index('time', inplace=True)\n",
    "\n",
    "points = len(cora_stations)\n",
    "t = np.zeros((num_ts, points, 3), dtype=float)\n",
    "\n",
    "for i in range(0,len(cora_stations)):\n",
    "       mean_zeta[:,i] = zeta_tslice[:,mapped_triangle[i]].mean(dim='node')\n",
    "        \n",
    "for t_i in range(0, 3):\n",
    "    t[:, :, t_i] = zeta_tslice[:, mapped_triangle[:, t_i]] * weights[:, t_i]\n",
    "    \n",
    "zeta_point = np.sum(t, axis=2) / np.sum(weights, axis=1)\n",
    "zeta_point[np.isnan(zeta_point)] = mean_zeta[np.isnan(zeta_point)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dde2bf-c378-468d-82c3-a401652264a2",
   "metadata": {},
   "source": [
    "## If you want to write out files, you can use this block. It will also format the .csv files for use with the NOAA Tidal Analysis Datum Calculator if you want to convert the CORA data from mean sea level to a different tidal datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5mLkwjTrTtK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "5mLkwjTrTtK9",
    "outputId": "40895ce6-9bb8-4d6a-8219-328ef3f204a9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "zeta_df = pd.DataFrame({'time': dt_range})\n",
    "\n",
    "for i in range(56,57):\n",
    "    zeta_df['zeta'] = zeta_point[:,i]\n",
    "    zeta_df = zeta_df.round(3) # round the wl digits to 3 for use with the TAD calculator\n",
    "    zeta_df['time'] = pd.to_datetime(zeta_df['time'])\n",
    "    zeta_df['time'] = zeta_df['time'].dt.strftime('%m/%d/%Y %H:%M') # change the datetime format for use with the TAD calculator\n",
    "\n",
    "    wse_filename = str(cora_stations.id.iloc[i]) + '_from_model_mesh' + '.csv' # create filename with station id and time range\n",
    "    zeta_df[['time',\"zeta\"]].to_csv(wse_filename,index=False) # write the files to .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b692a4-f2fb-4b54-b611-92706cefe2a5",
   "metadata": {},
   "source": [
    "**Plot the time series data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RoWce5cCwoX6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "id": "RoWce5cCwoX6",
    "outputId": "a992630f-012e-44bc-b60f-c2c19095c233"
   },
   "outputs": [],
   "source": [
    "title = \"Hourly Water Levels\"\n",
    "ylabel = \"MSL, m\"\n",
    "\n",
    "for i in range(61,63):\n",
    "\n",
    "  plt.plot(dt_range,zeta_point[:,i],label=cora_stations['id'].iloc[i])\n",
    "  plt.title(title)\n",
    "  plt.xlabel('')\n",
    "  plt.ylabel(ylabel)\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DMAC_python",
   "language": "python",
   "name": "dmac_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
